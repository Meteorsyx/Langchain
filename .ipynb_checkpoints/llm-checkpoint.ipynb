{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04682c2-06c3-430b-a322-353e7eca42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://gpt4wolfai.openai.azure.com/\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"086819469e544eedb793b9870a82f0d8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  deployment_name=\"gpt-4\",\n",
    "  model_name=\"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79721e28-26ce-4037-9660-9c29d7425f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type 给",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm(\u001b[39m\"\u001b[39;49m\u001b[39m给我两个字\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:642\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    636\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    637\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    641\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 642\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[0;32m    643\u001b[0m         [messages], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    644\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    645\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    646\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:383\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[0;32m    382\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[1;32m--> 383\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    384\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[0;32m    385\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[0;32m    386\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[0;32m    387\u001b[0m ]\n\u001b[0;32m    388\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:373\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[0;32m    371\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 373\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[0;32m    374\u001b[0m                 m,\n\u001b[0;32m    375\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    376\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    377\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    378\u001b[0m             )\n\u001b[0;32m    379\u001b[0m         )\n\u001b[0;32m    380\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    381\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:529\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    526\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 529\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m    530\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:429\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     stream_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream(\n\u001b[0;32m    426\u001b[0m         messages, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m     \u001b[39mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m--> 429\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_message_dicts(messages, stop)\n\u001b[0;32m    430\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m    431\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    432\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m: stream} \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}),\n\u001b[0;32m    433\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    434\u001b[0m }\n\u001b[0;32m    435\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    436\u001b[0m     messages\u001b[39m=\u001b[39mmessage_dicts, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    437\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:448\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`stop` found in both the input and default params.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    447\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[1;32m--> 448\u001b[0m message_dicts \u001b[39m=\u001b[39m [convert_message_to_dict(m) \u001b[39mfor\u001b[39;49;00m m \u001b[39min\u001b[39;49;00m messages]\n\u001b[0;32m    449\u001b[0m \u001b[39mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\chat_models\\openai.py:448\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`stop` found in both the input and default params.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    447\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[1;32m--> 448\u001b[0m message_dicts \u001b[39m=\u001b[39m [convert_message_to_dict(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[0;32m    449\u001b[0m \u001b[39mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\adapters\\openai.py:145\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    139\u001b[0m     message_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m    140\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtool\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: message\u001b[39m.\u001b[39mcontent,\n\u001b[0;32m    142\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtool_call_id\u001b[39m\u001b[39m\"\u001b[39m: message\u001b[39m.\u001b[39mtool_call_id,\n\u001b[0;32m    143\u001b[0m     }\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unknown type \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m message\u001b[39m.\u001b[39madditional_kwargs:\n\u001b[0;32m    147\u001b[0m     message_dict[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39madditional_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Got unknown type 给"
     ]
    }
   ],
   "source": [
    "llm(\"给我两个字\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94e3ed90-1454-4961-b94a-cc671647d3b3",
   "metadata": {},
   "source": [
    "# Title1\n",
    "## title2\n",
    "\n",
    "- list1\n",
    "- list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c625b-5986-4b95-8b08-104722ade36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
